{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escala de variables\n",
    "\n",
    "### Que tan importante es la magnitud de una variable?\n",
    "\n",
    "En modelos de regresión lineal, la escala o magnitud de una variable es importante. En modelos lineales de la forma **y = w x + b**, el coeficiente de regresión w representa el cambio esperado en y por una unidad de cambio in x (el predictor). Por lo tanto, la magnitud de w es parcialmente determinada por la magnitud de las unidades en x. Si x es una variable de distancia, simplemente cambiando la escala de kilómetros a millas causa un cambio en la magnitud del coeficiente. \n",
    "\n",
    "Adicionalmente, en situaciones donde se busca estimar y, utilizando múltiples variables x1, x2, ...xn, las variables cuyas escala de valores sean mayores dominarán sobre aquellas que tengan un rango de valores menor.\n",
    "\n",
    "Por otro lado, el algoritmo de descenso de gradiente converge más rápido cuando todos las variables independientes (x1 a xn) tienen una escala de valores similar. De modo que tener variables con magnitudes similares es también bastante útil para las Redes Neuronales.\n",
    "\n",
    "Con las Máquinas de Soporte Vectorial o Máquinas de Vectores de Soporte (Support Vector Machines SVM), la normalización de la escala de las variables puede reducir el tiempo requerido para encontrar los vectores de soporte. \n",
    "\n",
    "Finalmente, métodos que usan Distancias Euclidianas o distancias en general, también son sensibles a las variaciones en la magnitud o escala de las variables, ya que intrínsecamente afectan el cálculo de las distancias. Por lo tanto, el escalamiento de las variables es necesario para métodos que utilicen distancias como   K-vecinos cercanos o K-NN (K Nearest Neighbours) y aglomeramiento por  k-means.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "#### La magnitud o escala de las variables es importante porque:\n",
    "\n",
    "- El coeficiente de regresión está directamente influenciado por la escala de la variable.\n",
    "- Variables con mayor magnitud/rango de valores dominan sobre aquellas con un rango menor.\n",
    "- El algoritmo del descenso de gradiente converge más rápido cuando las variables tienen escalas similares.\n",
    "- El escalamiento de las variables ayuda a reducir el tiempo para encontrar los vectores soporte para SVMs.\n",
    "- Medidas de distancia como la Euclidiana son sensibles a las escalas de magnitud de las variables.\n",
    "\n",
    "#### Los modelos de machine learning que se afectan más por la escala o magnitud de las variables son:\n",
    "\n",
    "- Regresiones Lineales y Logísticas\n",
    "- Redes Neuronales \n",
    "- Máquinas de Soporte Vectorial\n",
    "- KNN\n",
    "- Agrupación K-means \n",
    "- Análisis Discriminante Lineal (LDA)\n",
    "- Análisis de Componentes Principales (PCA)\n",
    "\n",
    "#### Los modelos de machine learning menos sensibles a  la escala o magnitud de las variables son aquellos basados en árboles:\n",
    "\n",
    "- Árboles de Clasificación y Regresión. \n",
    "- Bosques Aleatorios (Random Forest) \n",
    "- Árboles de Potenciación del gradiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================\n",
    "\n",
    "## En este Demo\n",
    "\n",
    "Vamos a estudiar el efector de la magnitud de las variables en el desempeño de los diferentes modelos de machine learning.\n",
    "\n",
    "Usaremos los datos del Titanic.\n",
    "\n",
    "- Para descargar los datos por favor referirse a la lección **Datasets** en la **Sección 1** del curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# importar varios modelos de machine learning \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# para escalar las variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# para evaluar el desempeño y separar datos en entrenamiento y prueba\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos con las variables numéricas únicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>211.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived      age      fare\n",
       "0       1         1  29.0000  211.3375\n",
       "1       1         1   0.9167  151.5500\n",
       "2       1         0   2.0000  151.5500\n",
       "3       1         0  30.0000  151.5500\n",
       "4       1         0  25.0000  151.5500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar las variables numéricas del Titanic\n",
    "\n",
    "data = pd.read_csv('../titanic.csv',\n",
    "                   usecols=['pclass', 'age', 'fare', 'survived'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>14.413500</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived          age         fare\n",
       "count  1309.000000  1309.000000  1046.000000  1308.000000\n",
       "mean      2.294882     0.381971    29.881135    33.295479\n",
       "std       0.837836     0.486055    14.413500    51.758668\n",
       "min       1.000000     0.000000     0.166700     0.000000\n",
       "25%       2.000000     0.000000    21.000000     7.895800\n",
       "50%       3.000000     0.000000    28.000000    14.454200\n",
       "75%       3.000000     1.000000    39.000000    31.275000\n",
       "max       3.000000     1.000000    80.000000   512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# miremos los valores de cada una de las variables\n",
    "# para darnos una idea de la mgnitud/escala de las variables\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la variable fare varia entre 0 y 512, age entre 0 y 80, y class entre 0 y 3. Las variables tienen claramente diferentes escalas de magnitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rango: pclass 2\n",
      "rango: age 79.8333\n",
      "rango: fare 512.3292\n"
     ]
    }
   ],
   "source": [
    "# calculemos el rango\n",
    "\n",
    "for col in ['pclass', 'age', 'fare']:\n",
    "    print('rango:',col, data[col].max() - data[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rango de valores que puede tomar cada una de las variables es diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((916, 3), (393, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separemos los datos en entrenamiento y prueba\n",
    "# los datos del titanic contienen datos ausentes\n",
    "# para este demo, los sustituiremos con 0s.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['pclass', 'age', 'fare']].fillna(0),\n",
    "    data.survived,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalamiento de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este demo, normalizaremos las variables entre 0 y 1, usando  el MinMaxScaler de Scikit-learn. Para aprender más acerca de este escalamiento por favor visita la página de internet de Scikit-learn [website](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "La transformación: \n",
    "\n",
    "X_rescaled = X - X.min() / (X.max - X.min()\n",
    "\n",
    "y para transformar de vuelta las variables normalizadas a su escala original:\n",
    "\n",
    "X = X_rescaled * (max - min) + min\n",
    "\n",
    "**Hay una sección dedicada al escalamiento de las variables más adelante en el curso, donde explicaremos esta y otras técnicas de normalización en detalle**. Por ahora, continuemos con el demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalemos las variables entre 0 y 1.\n",
    "\n",
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# ajustar el scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# re escalar los datos\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media:  [0.64628821 0.33048359 0.06349833]\n",
      "Desviación Estandard:  [0.42105785 0.23332045 0.09250036]\n",
      "Valor Mínimo:  [0. 0. 0.]\n",
      "Valor Máximo:  [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#veamos los datos normalizados\n",
    "\n",
    "print('Media: ', X_train_scaled.mean(axis=0))\n",
    "print('Desviación Estandard: ', X_train_scaled.std(axis=0))\n",
    "print('Valor Mínimo: ', X_train_scaled.min(axis=0))\n",
    "print('Valor Máximo: ', X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, los valores máximos de todas las variables es 1, y el valor mínimo es 0, como era de esperarse después de la normalización. Ahora todas las variables tienen una escala similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística \n",
    "\n",
    "Evaluemos el efecto del escalamiento de las variables en una regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Regresión logística roc-auc: 0.6793181006244372\n",
      "Segmento de prueba\n",
      "Regresión logística roc-auc: 0.7175488081411426\n"
     ]
    }
   ],
   "source": [
    "# modelo construido con variables sin escalar\n",
    "\n",
    "# Definición del Modelo\n",
    "logit = LogisticRegression(\n",
    "    random_state=44,\n",
    "    C=1000,  # valor alto para prevenir regularización\n",
    "    solver='lbfgs')\n",
    "\n",
    "# entrenamiento del modelo \n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# evaluación del desempeño \n",
    "print('Segmento de entrenamiento')\n",
    "pred = logit.predict_proba(X_train)\n",
    "print('Regresión logística roc-auc: {}'.format(\n",
    "    roc_auc_score(y_train, pred[:, 1])))\n",
    "print('Segmento de prueba')\n",
    "pred = logit.predict_proba(X_test)\n",
    "print('Regresión logística roc-auc: {}'.format(\n",
    "    roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.71428242, -0.00923013,  0.00425235]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# miremos los  coeficientes\n",
    "logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Regresión logística roc-auc: 0.6793281640744896\n",
      "Segmento de prueba\n",
      "Regresión logística roc-auc: 0.7175488081411426\n"
     ]
    }
   ],
   "source": [
    "# modelo construido con variables normalizadas\n",
    "\n",
    "# Definición del Modelo\n",
    "logit = LogisticRegression(\n",
    "    random_state=44,\n",
    "    C=1000,  # valor alto para prevenir regularización\n",
    "    solver='lbfgs')\n",
    "\n",
    "# entrenamiento del modelo con los datos re-escalados\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación del desempeño \n",
    "print('Segmento de entrenamiento')\n",
    "pred = logit.predict_proba(X_train_scaled)\n",
    "print('Regresión logística roc-auc: {}'.format(\n",
    "    roc_auc_score(y_train, pred[:, 1])))\n",
    "print('Segmento de prueba')\n",
    "pred = logit.predict_proba(X_test_scaled)\n",
    "print('Regresión logística roc-auc: {}'.format(\n",
    "    roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.42875872, -0.68293349,  2.17646757]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el desempeño de la regresión logística no cambio cuando usamos los datos normalizados ( comparando el roc-auc para el segmento de prueba y entrenamiento para modelos con y sin variables escaladas).\n",
    "\n",
    "Sin embargo, cuando vemos los coeficientes vemos una gran diferencia en sus valores. Esto es porque la magnitud de las variables estaba afectando los coeficientes. Despues del escalamiento, todas las 3 variables tienen relativamente el mismo efecto (coeficientes) con respecto a 'survival', mientras que sin el escalamiento, estariamos más inclinados a pensar que pclass dominaba en la predicción de la tasa de supervivencia survival (el coeficiente de pclass es dos ordenes mayor que los coeficientes de las otras dos variables, cuando el modelo se entrena sobre las variables sin escalar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de Soporte Vectorial SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "SVM roc-auc: 0.8824010385480454\n",
      "Segmento de prueba\n",
      "SVM roc-auc: 0.6617443725457663\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables sin normalizar\n",
    "\n",
    "# definición del modelo\n",
    "SVM_model = SVC(random_state=44, probability=True, gamma='auto')\n",
    "\n",
    "#  entrenamiento del modelo\n",
    "SVM_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluación del desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = SVM_model.predict_proba(X_train)\n",
    "print('SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "print('Segmento de prueba')\n",
    "pred = SVM_model.predict_proba(X_test)\n",
    "print('SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "SVM roc-auc: 0.6784778025450466\n",
      "Segmento de prueba\n",
      "SVM roc-auc: 0.683894696089818\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables normalizadas\n",
    "\n",
    "# definición del modelo\n",
    "SVM_model = SVC(random_state=44, probability=True, gamma='auto')\n",
    "\n",
    "# entrenamiento del modelo\n",
    "SVM_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación del desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = SVM_model.predict_proba(X_train_scaled)\n",
    "print('SVM roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "print('Segmento de prueba')\n",
    "pred = SVM_model.predict_proba(X_test_scaled)\n",
    "print('SVM roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El escalamiento de las variables mejoró el desempeño de SVMs. Luego de la normalización el modelo no sobre-ajusta a los datos de entrenamiento (compara el roc-auc en el set de entrenamiento para el modelo sin escalar vs el roc-auc tras la normalización). Adicionalmente, el roc-auc para el segmento de prueba se incrementó también (0.66 vs 0.68)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Red Neuronal roc-auc: 0.6766814767106608\n",
      "Segmento de prueba\n",
      "Red Neuronal roc-auc: 0.7161108345777334\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables sin normalizar\n",
    "\n",
    "# definición del modelo\n",
    "NN_model = MLPClassifier(random_state=44, solver='sgd')\n",
    "\n",
    "# entrenamiento del modelo\n",
    "NN_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = NN_model.predict_proba(X_train)\n",
    "print('Red Neuronal roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Segmento de prueba')\n",
    "pred = NN_model.predict_proba(X_test)\n",
    "print('Red Neuronal roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Red Neuronal roc-auc: 0.6754939896044562\n",
      "Segmento de prueba\n",
      "Red Neuronal roc-auc: 0.7080913666279519\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables normalizadas\n",
    "\n",
    "# definición del modelo\n",
    "NN_model = MLPClassifier(random_state=44, solver='sgd')\n",
    "\n",
    "# entrenamiento del model\n",
    "NN_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = NN_model.predict_proba(X_train_scaled)\n",
    "print('Red Neuronal roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Segmento de prueba')\n",
    "pred = NN_model.predict_proba(X_test_scaled)\n",
    "print('Red Neuronal roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no ha habido un gran cambio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-vecinos cercanos (KNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "KNN roc-auc: 0.855810887646612\n",
      "Segmento de prueba\n",
      "KNN roc-auc: 0.6655467064874732\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables sin normalizar\n",
    "\n",
    "# definición del modelo\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# entrenamiento del model\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = KNN.predict_proba(X_train)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Segmento de prueba')\n",
    "pred = KNN.predict_proba(X_test)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "KNN roc-auc: 0.8600954015064985\n",
      "Segmento de prueba\n",
      "KNN roc-auc: 0.6998644986449865\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables normalizadas\n",
    "\n",
    "# definición del modelo\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# entrenamiento del model\n",
    "KNN.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = KNN.predict_proba(X_train_scaled)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Segmento de prueba')\n",
    "pred = KNN.predict_proba(X_test_scaled)\n",
    "print('KNN roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que para KNN el escalamiento también ha mejorado el desempeño del modelo. El modelo construido con las variables normalizadas tiene una mejor generalización, ya que el roc-auc es más alto en el segmento de prueba tras escalar las variables.\n",
    "\n",
    "Ambos modelos KNN están sobre-ajustando el segmento de entrenamiento. Deberíamos ajustar los parámetros del modelo para reducir el sobre-ajuste, pero esto está por fuera del alcance de este demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Random Forests roc-auc: 0.9866810238554083\n",
      "Segmento de prueba\n",
      "Random Forests roc-auc: 0.7326751838946961\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables sin normalizar\n",
    "\n",
    "# definición del modelo\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# entrenamiento del model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = rf.predict_proba(X_train)\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "print('Segmento de prueba')\n",
    "pred = rf.predict_proba(X_test)\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "Random Forests roc-auc: 0.9867917218059866\n",
      "Segmento de prueba\n",
      "Random Forests roc-auc: 0.7312510370001659\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables normalizadas\n",
    "\n",
    "# definición del modelo\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "\n",
    "# entrenamiento del model\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = rf.predict_proba(X_train_scaled)\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Segmento de prueba')\n",
    "pred = rf.predict_proba(X_test_scaled)\n",
    "print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse, el desempeño de Random Forest fue el mismo independientemente de la normalización de las variables. Este modelo en particular, esta sobre-ajustando el segmento de entrenamiento. Por lo tanto es necesario ajustar los parámetros del modelo para mejorar la generalización, sin embargo esto está por fuera del alcance de este demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "AdaBoost roc-auc: 0.7970629821021541\n",
      "Test set\n",
      "AdaBoost roc-auc: 0.7473867595818815\n"
     ]
    }
   ],
   "source": [
    "# train adaboost on non-scaled features\n",
    "\n",
    "# call the model\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# entrenamiento del model\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = ada.predict_proba(X_train)\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Test set')\n",
    "pred = ada.predict_proba(X_test)\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmento de entrenamiento\n",
      "AdaBoost roc-auc: 0.7970629821021541\n",
      "Test set\n",
      "AdaBoost roc-auc: 0.7475250262706707\n"
     ]
    }
   ],
   "source": [
    "# Modelo con variables normalizadas\n",
    "\n",
    "# definición del modelo\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=44)\n",
    "\n",
    "# entrenamiento del model\n",
    "ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "# evaluación de desempeño\n",
    "print('Segmento de entrenamiento')\n",
    "pred = ada.predict_proba(X_train_scaled)\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "print('Test set')\n",
    "pred = ada.predict_proba(X_test_scaled)\n",
    "print('AdaBoost roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse,  el desempeño de AdaBoost no cambio con la  normalización de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Eso es todo por este demo. Esperamos que lo hayan disfrutado y nos vemos en el siguiente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feml",
   "language": "python",
   "name": "feml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
